{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a34fc24-9f07-40a5-be14-7c8df307b6e3",
   "metadata": {},
   "source": [
    "<sub>Developed by SeongKu Kang, August 2025 â€” Do not distribute</sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbcf726-d451-41ec-99fb-a008be208240",
   "metadata": {},
   "source": [
    "# ðŸ“˜ Guide to Using BERT\n",
    "\n",
    "To use BERT for classification, we need to understand two key steps:  \n",
    "1. **How raw text is converted into model inputs**  \n",
    "2. **How to interpret and leverage BERT outputs**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a34ff16-7891-4d43-aa26-0d16a719978e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56aab76a-6610-46fa-af27-ef3a750350b7",
   "metadata": {},
   "source": [
    "## [Part A] Understanding BERT Input\n",
    "This notebook focuses on the preprocessing step with Hugging Face's `AutoTokenizer`.  \n",
    "You will learn how to obtain the following inputs required by BERT:\n",
    "\n",
    "- `input_ids`: tokenized text represented as integer IDs  \n",
    "- `attention_mask`: binary mask (1 for real tokens, 0 for padding)  \n",
    "\n",
    "This illustrates the transformation from **raw string â†’ tokenized IDs â†’ BERT input tensors**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbf2390-e959-4f94-91c4-97c6e0056848",
   "metadata": {},
   "source": [
    "### ðŸ”Ž BERT Input Example\n",
    "\n",
    "When we feed raw texts into BERT, the tokenizer automatically performs several steps:\n",
    "\n",
    "1. **Add special tokens**  \n",
    "   - `[CLS]` (101) is added at the beginning of every sequence. It serves as a special representation for the whole sequence.  \n",
    "   - `[SEP]` (102) is added at the end of every sequence to mark separation (even for single sentences).\n",
    "\n",
    "2. **Convert tokens to IDs**  \n",
    "   - Each token is mapped to its corresponding integer ID in the BERT vocabulary.\n",
    "\n",
    "3. **Handle variable lengths**  \n",
    "   - Since sentences can have different lengths, BERT requires a fixed input length.  \n",
    "   - The tokenizer uses **padding (0)** to make all sequences the same length.  \n",
    "   - An **attention mask** is created, where `1` indicates real tokens and `0` indicates padding.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9c59167-6111-43ce-b29a-dd684fe1e44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Input IDs]:\n",
      " tensor([[  101, 26098, 18008,   102,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101, 13675, 23555,  2102, 18008,  2005,  4088, 16912,  2007,  9413,\n",
      "          7446,   102],\n",
      "        [  101, 22746,  1998, 26098, 16611,  2164, 17044,  1010, 18008,  1010,\n",
      "          1998,   102]])\n",
      "[Attention Mask]:\n",
      " tensor([[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Example texts with different lengths\n",
    "texts = [\n",
    "    \"Knitting hooks\",\n",
    "    \"Crochet hooks for beginners with ergonomic handle\",\n",
    "    \"Sewing and knitting accessories including needles, hooks, and more\"\n",
    "]\n",
    "\n",
    "# Tokenize with padding & truncation\n",
    "encoded = tokenizer(\n",
    "    texts,\n",
    "    padding=\"max_length\",   # pad to fixed length\n",
    "    truncation=True,        # truncate if longer than max_length\n",
    "    max_length=12,          # small value for illustration\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "print(\"[Input IDs]:\\n\", encoded[\"input_ids\"])\n",
    "print(\"[Attention Mask]:\\n\", encoded[\"attention_mask\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808c9a83-fc97-4eef-a015-eabc829f0095",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7686b6d8-8d36-487f-b037-daca943995e6",
   "metadata": {},
   "source": [
    "## [Part B] Understanding BERT Output\n",
    "\n",
    "When we feed tokenized inputs into BERT, the model returns several outputs.  \n",
    "For classification, the most important one is:\n",
    "\n",
    "- **`last_hidden_state`**  \n",
    "  Shape: `(batch_size, seq_len, hidden_size)`  \n",
    "  â†’ Contextual embedding for each token in the sequence.\n",
    "\n",
    "From `last_hidden_state`, we can derive two common sequence-level representations:\n",
    "\n",
    "1. **[CLS] token embedding**  \n",
    "   - The first token (`[CLS]`) is designed to capture the meaning of the entire sequence.  \n",
    "   - Example usage: `cls_embedding = outputs.last_hidden_state[:, 0]`  \n",
    "   - Shape: `(batch_size, hidden_size)`\n",
    "\n",
    "2. **Mean pooling**  \n",
    "   - Average all token embeddings across the sequence, weighted by the attention mask (ignoring padding).  \n",
    "   - Captures information from all tokens, not just the first one.  \n",
    "   - Example usage:  \n",
    "     ```python\n",
    "     mean_embedding = (outputs.last_hidden_state * attention_mask.unsqueeze(-1)).sum(1) \\\n",
    "                      / attention_mask.sum(1).unsqueeze(-1)\n",
    "     ```  \n",
    "   - Shape: `(batch_size, hidden_size)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b4a90cc-f4f2-4113-82b6-18d0b7216300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS Embedding Shape]: torch.Size([3, 768])\n",
      "[Mean-pooled Embedding Shape]: torch.Size([3, 768])\n",
      "\n",
      "Example CLS embedding (first 5 dims): tensor([-0.3316,  0.0918, -0.9048,  0.1675,  0.2810])\n",
      "Example Mean embedding (first 5 dims): tensor([ 0.3487, -0.2039, -0.7064,  0.1054,  0.3160])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "import torch\n",
    "\n",
    "# Load BERT model\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Forward pass\n",
    "with torch.no_grad():\n",
    "    outputs = model(**encoded)\n",
    "\n",
    "# CLS embedding (first token from last_hidden_state)\n",
    "cls_embedding = outputs.last_hidden_state[:, 0]   # (batch_size, hidden_size)\n",
    "\n",
    "# Mean pooling (mask out padding tokens)\n",
    "mean_embedding = (outputs.last_hidden_state * encoded[\"attention_mask\"].unsqueeze(-1)).sum(1) \\\n",
    "                 / encoded[\"attention_mask\"].sum(1).unsqueeze(-1)\n",
    "\n",
    "print(\"[CLS Embedding Shape]:\", cls_embedding.shape)\n",
    "print(\"[Mean-pooled Embedding Shape]:\", mean_embedding.shape)\n",
    "\n",
    "# (Optional) Show first 5 values for one example\n",
    "print(\"\\nExample CLS embedding (first 5 dims):\", cls_embedding[0][:5])\n",
    "print(\"Example Mean embedding (first 5 dims):\", mean_embedding[0][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af25da3-5e94-4533-a7ce-fd2e4055ca92",
   "metadata": {},
   "source": [
    "---\n",
    "## [Part C] Using BERT Mean-Pooled Embeddings\n",
    "\n",
    "In this assignment, we mainly use **fixed BERT mean-pooled embeddings** for efficiency (i.e., partial fine-tuning with fixed encoder).\n",
    "\n",
    "Instead of fine-tuning BERT every time, we pre-compute the embeddings once and reuse them.  \n",
    "\n",
    "You can extract and save these embeddings with the following code snippet.  \n",
    "*(You will need them in your assignments.)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ab2aac-219b-496f-b17e-5174ccd04052",
   "metadata": {},
   "source": [
    "### 1. Save corpus & query embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acaf5298-8c1b-45b6-ab9e-2da470e1a3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import json\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Path config\n",
    "ROOT = Path(\"./dataset\")\n",
    "CORPUS_PATH = ROOT / \"corpus.jsonl\" #product_id, title, description\n",
    "QUERY_PATH = ROOT / \"queries_1k.jsonl\" #query_id, query, product_id\n",
    "\n",
    "# Load PLM\n",
    "MODEL_NAME = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = BertModel.from_pretrained(MODEL_NAME).eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9daf6e36-05e1-457e-b506-627c6e95cc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "    \"\"\"\n",
    "    Apply mean pooling on BERT token embeddings, masking out padding tokens.\n",
    "\n",
    "    Args:\n",
    "        model_output: Output object from a BERT model (contains last_hidden_state).\n",
    "        attention_mask (torch.Tensor): Attention mask of shape (batch_size, seq_len),\n",
    "                                       where 1 = real token and 0 = padding.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Sentence embeddings of shape (batch_size, hidden_size).\n",
    "    \"\"\"\n",
    "    token_embeddings = model_output.last_hidden_state\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, dim=1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(dim=1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask\n",
    "\n",
    "def encode_texts(texts, batch_size=64):\n",
    "    \"\"\"\n",
    "    Encode a list of texts into mean-pooled BERT embeddings.\n",
    "\n",
    "    Args:\n",
    "        texts (list of str): Input texts to encode.\n",
    "        batch_size (int, optional): Batch size for encoding. Default is 64.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Tensor of shape (len(texts), hidden_size) containing embeddings.\n",
    "    \"\"\"\n",
    "    all_embeddings = []\n",
    "\n",
    "    # Process texts in mini-batches\n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch = texts[i:i+batch_size]\n",
    "\n",
    "        # Tokenize and move to model device\n",
    "        encoded = tokenizer(\n",
    "            batch,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(model.device)\n",
    "\n",
    "        # Forward pass through BERT\n",
    "        with torch.no_grad():\n",
    "            output = model(**encoded)\n",
    "\n",
    "        # Mean pooling (exclude padding tokens)\n",
    "        embeddings = mean_pooling(output, encoded[\"attention_mask\"])\n",
    "        all_embeddings.append(embeddings.cpu())\n",
    "\n",
    "    # Concatenate all batch embeddings\n",
    "    return torch.cat(all_embeddings, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60e6850e-436c-435f-8eca-8a51cb593e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 617/617 [05:46<00:00,  1.78it/s]\n"
     ]
    }
   ],
   "source": [
    "# Encode corpus with BERT (mean pooling)\n",
    "pid2text = load_corpus(CORPUS_PATH)              # Load corpus as {pid: text} dictionary\n",
    "corpus_ids, corpus_texts = dict2list(pid2text)   # Convert dict â†’ (ids, texts) lists\n",
    "\n",
    "corpus_emb = encode_texts(corpus_texts)          # Compute mean-pooled BERT embeddings\n",
    "torch.save({\"ids\": corpus_ids, \"embeddings\": corpus_emb}, ROOT / \"corpus_bert_mean.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f57b103a-344d-4fbf-93bd-248318ecfdc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:01<00:00,  8.81it/s]\n"
     ]
    }
   ],
   "source": [
    "# Encode training queries with BERT (mean pooling)\n",
    "qid2text = load_queries(QUERY_PATH)               # Load queries as {qid: text} dictionary\n",
    "query_ids, query_texts = dict2list(qid2text)      # Convert dict â†’ (ids, texts) lists\n",
    "\n",
    "query_emb = encode_texts(query_texts)             # Compute mean-pooled BERT embeddings\n",
    "\n",
    "torch.save({\"ids\": query_ids, \"embeddings\": query_emb}, ROOT / \"queries_1k_bert_mean.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffee5185-6e10-4f3c-adb4-e19095110c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 51.81it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 53.11it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 49.60it/s]\n"
     ]
    }
   ],
   "source": [
    "TEST_QUERY_PATH = ROOT / \"queries_test.jsonl\"\n",
    "\n",
    "# Encode test queries (set 1) with BERT (mean pooling)\n",
    "qid2text_test = load_queries(TEST_QUERY_PATH)           # Load as {qid: text}\n",
    "query_ids_test, query_texts_test1 = dict2list(qid2text_test)  # Convert to lists\n",
    "query_emb_test = encode_texts(query_texts_test)         # Compute embeddings\n",
    "\n",
    "torch.save({\"ids\": query_ids_test, \"embeddings\": query_emb_test}, ROOT / \"test_queries_bert_mean.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b5e117-2485-46ef-88fa-295a07e0b763",
   "metadata": {},
   "source": [
    "### 2. Category class label embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba05f0dd-edc8-4d73-a7a6-8fe10652c2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = Path(\"dataset\")\n",
    "LABEL_MAP_PATH = ROOT / \"category_classification\"\n",
    "LABEL_TEXT_PATH = LABEL_MAP_PATH / \"labelid2label.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b5f57f3-6061-4820-81cb-b6628972db0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:01<00:00,  7.58it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 18.55it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(LABEL_TEXT_PATH) as f:\n",
    "    id2label = json.load(f)\n",
    "\n",
    "label_ids = list(map(int, id2label.keys()))\n",
    "label_texts = [id2label[str(i)] for i in label_ids]\n",
    "\n",
    "# label encoding\n",
    "batch_size = 64\n",
    "all_embeddings = []\n",
    "for i in tqdm(range(0, len(label_texts), batch_size)):\n",
    "    batch = label_texts[i:i+batch_size]\n",
    "    encoded = tokenizer(batch, padding=True, truncation=True, max_length=128, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        output = model(**encoded)\n",
    "    emb = mean_pooling(output, encoded[\"attention_mask\"])  # (B, D)\n",
    "    all_embeddings.append(emb.cpu())\n",
    "\n",
    "label_embeddings = torch.cat(all_embeddings, dim=0)  # (C, D)\n",
    "torch.save({\"ids\": label_ids, \"embeddings\": label_embeddings}, LABEL_MAP_PATH / \"category_labels_bert_mean.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798c3847-e7ae-479c-8809-9c6dfa6f1228",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esci-env",
   "language": "python",
   "name": "esci-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
