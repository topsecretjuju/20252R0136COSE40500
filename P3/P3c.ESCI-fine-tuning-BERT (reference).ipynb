{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f23c0132-ac9b-44ae-98de-d2e34bc0b66a",
   "metadata": {},
   "source": [
    "<sub>Developed by SeongKu Kang, August 2025 — Do not distribute</sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1429b2cb-7db0-41f3-98e8-29bf7c067e04",
   "metadata": {},
   "source": [
    "# Task 2: Fine-tuning with Cross-Encoders\n",
    "\n",
    "In this notebook, we shift our focus from representation-based models (e.g., dual encoders that independently encode queries and documents) to **cross-encoders**, where a query and a document are processed *together* through the same BERT model.  \n",
    "\n",
    "The key idea of a cross-encoder is that it allows the model to **jointly attend** to both the query and the document tokens. Instead of computing embeddings separately and then measuring similarity, the cross-encoder takes the concatenated sequence:\n",
    "\n",
    "`[CLS] query tokens [SEP] document tokens [SEP]`\n",
    "\n",
    "and produces a single contextualized representation. The `[CLS]` token is then used for classification, such as predicting the relevance of the document to the query.  \n",
    "\n",
    "This approach is particularly suited for **ESCI (Exact, Substitute, Complement, Irrelevant)** classification, where fine-grained semantic distinctions matter. Cross-encoders capture subtle interactions between query and document words (e.g., synonyms, negations, product attributes) that embedding-only approaches often miss.  \n",
    "\n",
    "Although cross-encoders are more computationally expensive at inference time, they typically deliver **higher accuracy** for tasks requiring nuanced semantic matching.  \n",
    "\n",
    "In this notebook, we will:\n",
    "1. Format query–document pairs into BERT inputs.  \n",
    "2. Fine-tune a pre-trained BERT model with supervised ESCI labels.  \n",
    "3. Evaluate classification performance.  \n",
    "\n",
    "⚠️ **Note**   \n",
    "This notebook may take a long time to run, since it repeatedly encodes texts with BERT.  \n",
    "It is provided mainly for **reference**, and you are encouraged to review the workflow rather than execute every cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acac5aeb-29bb-4687-89cc-2a28f2a14be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from utils import * \n",
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, ConcatDataset\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6f5937f-50c1-43de-b833-204caf5a4026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path config (Cross-encoder setting: on-the-fly encoding, no precomputed embeddings used)\n",
    "ROOT = Path(\"dataset\")\n",
    "\n",
    "pid2text = load_corpus(ROOT / \"corpus.jsonl\")\n",
    "qid2text = load_queries(ROOT / \"queries_1k.jsonl\")\n",
    "test_qid2text = load_queries(ROOT / \"queries_test.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "149a3c62-4c87-46de-b325-57c6e7846af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   query-id   corpus-id label  label_idx\n",
       " 0     17397  B07R9HPJPW     E          0\n",
       " 1     17397  B07Q34YJ4T     E          0\n",
       " 2     17397  B07NH217CV     E          0,\n",
       "    query-id   corpus-id label  label_idx\n",
       " 0     12712  B081FY5ZYQ     S          1\n",
       " 1     12712  B07X45P8C3     S          1\n",
       " 2     12712  B07V9PPK61     S          1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === ESCI label mapping ===\n",
    "esci_label2id = {\"E\": 0, \"S\": 1, \"C\": 2, \"I\": 3}\n",
    "esci_id2label = {0: \"E\", 1: \"S\", 2: \"C\", 3: \"I\"}\n",
    "\n",
    "def load_qrels(path, esci_label2id):\n",
    "    \"\"\"\n",
    "    Load qrels file (query-document relevance labels).\n",
    "    - Keeps only rows with ESCI labels (E/S/C/I).\n",
    "    - Maps string labels to numeric IDs.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path, sep=\"\\t\", header=0)        # read TSV with header\n",
    "    df = df[df[\"label\"].isin(esci_label2id)]          # filter invalid labels\n",
    "    df[\"label_idx\"] = df[\"label\"].map(esci_label2id)  # map to numeric IDs\n",
    "    return df\n",
    "\n",
    "# === Load qrels (train & test) ===\n",
    "QRELS_TRAIN_PATH = ROOT / \"qrels_1k.tsv\"\n",
    "QRELS_TEST_PATH = ROOT / \"qrels_test.tsv\"\n",
    "\n",
    "train_qrels_df = load_qrels(QRELS_TRAIN_PATH, esci_label2id)\n",
    "test_qrels_df = load_qrels(QRELS_TEST_PATH, esci_label2id)\n",
    "\n",
    "train_qrels_df.head(3), test_qrels_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e679f584-e3c3-4371-8d0d-9162d526c5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Train triplets: 20303\n",
      "# Test triplets:  10149\n"
     ]
    }
   ],
   "source": [
    "def build_triplets(qrels_df):\n",
    "    \"\"\"\n",
    "    Build (query_id, product_id, label) triplets from qrels dataframe.\n",
    "    Args:\n",
    "        qrels_df: DataFrame where each row = (qid, pid, label)\n",
    "    Returns:\n",
    "        list of tuples: [(qid, pid, label), ...]\n",
    "    \"\"\"\n",
    "    triplets = []\n",
    "    for row in qrels_df.itertuples(index=False):\n",
    "        qid = row[0]      # query ID\n",
    "        pid = row[1]      # product/document ID\n",
    "        label = row[-1]   # relevance label\n",
    "        triplets.append((qid, pid, label))\n",
    "    return triplets\n",
    "\n",
    "# Build train/test triplets\n",
    "train_triplets = build_triplets(train_qrels_df)\n",
    "test_triplets = build_triplets(test_qrels_df)\n",
    "\n",
    "print(f\"# Train triplets: {len(train_triplets)}\")\n",
    "print(f\"# Test triplets:  {len(test_triplets)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff63a132-7d39-4aee-98a0-76b7ecef8b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEncoderDataset(Dataset):\n",
    "    def __init__(self, triplets, qid2text, pid2text, tokenizer, max_length=512):\n",
    "        \"\"\"\n",
    "        Cross-encoder dataset: each instance is (query, document, label)\n",
    "        Args:\n",
    "            triplets: list of (qid, pid, label)\n",
    "            qid2text: dict mapping query IDs to query text\n",
    "            pid2text: dict mapping product IDs to document text\n",
    "            tokenizer: HuggingFace tokenizer for BERT/Transformer\n",
    "            max_length: maximum sequence length for tokenization\n",
    "        \"\"\"\n",
    "        self.pairs = []\n",
    "        for qid, pid, label in triplets:\n",
    "            if qid in qid2text and pid in pid2text:  # safeguard\n",
    "                self.pairs.append((qid2text[qid], pid2text[pid], label))\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        query, doc, label = self.pairs[idx]\n",
    "\n",
    "        # Tokenize query–document pair for cross-encoder input\n",
    "        encoded = self.tokenizer(\n",
    "            query,\n",
    "            doc,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": encoded[\"input_ids\"].squeeze(0),       # token IDs (query+doc packed together)\n",
    "            \"attention_mask\": encoded[\"attention_mask\"].squeeze(0), # 1 = real token, 0 = padding\n",
    "            \"y\": torch.tensor(label, dtype=torch.long)          # classification/regression label\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db847562-49ec-4364-b158-5b6213c72b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def evaluate(model, dataloader, device=\"cpu\", num_classes=None):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "            y = batch[\"y\"].to(device)\n",
    "            logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            all_preds.extend(preds.cpu().tolist())\n",
    "            all_labels.extend(y.cpu().tolist())\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    f1_macro = f1_score(all_labels, all_preds, average=\"macro\", zero_division=0)\n",
    "\n",
    "    # === Per-class accuracy 계산 ===\n",
    "    class_correct = defaultdict(int)\n",
    "    class_total = defaultdict(int)\n",
    "    \n",
    "    for y_true, y_pred in zip(all_labels, all_preds):\n",
    "        class_total[y_true] += 1\n",
    "        if y_true == y_pred:\n",
    "            class_correct[y_true] += 1\n",
    "\n",
    "    per_class_acc = {}\n",
    "    class_range = range(num_classes) if num_classes is not None else sorted(class_total.keys())\n",
    "    for cls in class_range:\n",
    "        total = class_total[cls]\n",
    "        correct = class_correct[cls]\n",
    "        per_class_acc[cls] = correct / total if total > 0 else 0.0\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"f1_macro\": f1_macro,\n",
    "        \"per_class_accuracy\": per_class_acc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "077449c1-9655-4851-9f5f-4700b8a045f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "class CrossEncoderESCI(nn.Module):\n",
    "    def __init__(self, model_name=\"bert-base-uncased\", num_labels=4):\n",
    "        super().__init__()\n",
    "        # Pretrained BERT (or any Transformer encoder)\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        # Linear classifier: [CLS] hidden vector → num_labels\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids=None):\n",
    "        # BERT encoding\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        # CLS token embedding (batch_size × hidden_size)\n",
    "        cls_output = outputs.last_hidden_state[:, 0, :]\n",
    "        # Classification logits (batch_size × num_labels)\n",
    "        logits = self.classifier(cls_output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "110700f8-692e-4ad5-8a7e-a9385f25bb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "test_dataset = CrossEncoderDataset(test_triplets, test_qid2text, pid2text, tokenizer)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)\n",
    "\n",
    "results_dict = {'valid':{}, 'test': {}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "108af33a-4a37-400a-9a08-f8d5e8d9f035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Split into train/validation sets ===\n",
    "random.shuffle(train_triplets)  \n",
    "val_size = int(len(train_triplets) * 0.2)  \n",
    "val_triplets = train_triplets[:val_size]   # first 20% for validation\n",
    "train_triplets = train_triplets[val_size:] # remaining 80% for training\n",
    "\n",
    "# === Build datasets/loaders ===\n",
    "train_dataset = CrossEncoderDataset(train_triplets, qid2text, pid2text, tokenizer)\n",
    "val_dataset = CrossEncoderDataset(val_triplets, qid2text, pid2text, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)   # shuffle for training\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)      # no shuffle for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96c01e30-35e9-41ca-9370-68b8d4222d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Initialize model and optimizer ===\n",
    "model = CrossEncoderESCI(model_name=\"bert-base-uncased\", num_labels=4).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)  # AdamW is standard for transformer fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f506a10-7d4c-4403-9676-44bca80eea54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 508/508 [05:35<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Train Loss: 1.0564\n",
      "[VAL ] Acc: 0.5953 | F1-macro: 0.4423 *\n",
      "        E: 0.9110 | S: 0.3331 | C: 0.0510 | I: 0.4214\n",
      "[TEST] Acc: 0.5061 | F1-macro: 0.2926\n",
      "        E: 0.9074 | S: 0.1606 | C: 0.0000 | I: 0.1916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 508/508 [05:35<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] Train Loss: 0.7908\n",
      "[VAL ] Acc: 0.6771 | F1-macro: 0.6270 *\n",
      "        E: 0.7871 | S: 0.6445 | C: 0.4847 | I: 0.5036\n",
      "[TEST] Acc: 0.5269 | F1-macro: 0.4099\n",
      "        E: 0.6924 | S: 0.4829 | C: 0.1499 | I: 0.2535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:  22%|█████████████████████████████████████▏                                                                                                                                    | 111/508 [01:12<04:22,  1.51it/s]"
     ]
    }
   ],
   "source": [
    "best_val_acc = -1\n",
    "best_model_state = None\n",
    "patience = 5\n",
    "patience_counter = 0\n",
    "\n",
    "val_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "EPOCHS = 500\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch}\"):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        y = batch[\"y\"].to(device)\n",
    "        logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"[Epoch {epoch}] Train Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # === Validation ===\n",
    "    val_result = evaluate(model, val_loader, device=device)\n",
    "    val_acc = val_result[\"f1_macro\"]\n",
    "    val_acc_list.append(val_acc)\n",
    "\n",
    "    is_improved = val_acc > best_val_acc\n",
    "    print_eval_result_esci(val_result, stage=\"val\", is_improved=is_improved)\n",
    "\n",
    "    # === Test ===\n",
    "    test_result = evaluate(model, test_loader, device=device)\n",
    "    test_acc = test_result[\"f1_macro\"]\n",
    "    test_acc_list.append(test_acc)\n",
    "    print_eval_result_esci(test_result, stage=\"test\")\n",
    "\n",
    "    # === Update best model ===\n",
    "    if is_improved:\n",
    "        best_val_acc = val_acc\n",
    "        best_model_state = copy.deepcopy(model.state_dict())\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    # === Early stopping ===\n",
    "    if patience_counter >= patience:\n",
    "        print(f\"[Early Stopping] No improvement for {patience} consecutive epochs.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1766017-f6bd-4376-b81c-2daf00738699",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(best_model_state)\n",
    "final_test_result = evaluate(model, test_loader, device=device)\n",
    "print_eval_result_esci(final_test_result, stage=\"final_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164f3534-53e9-4c65-8f1e-1a8b82e87e63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e7586a-01d4-4fcd-b7bc-6d3006854091",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esci-env",
   "language": "python",
   "name": "esci-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
