{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edf3a4d1-ab59-4e8e-9a75-24e58cd3f6b7",
   "metadata": {},
   "source": [
    "<sub>Developed by SeongKu Kang, August 2025 ‚Äî Do not distribute</sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4883b6c",
   "metadata": {},
   "source": [
    "# üìò Task 1: Product category classification with no label (Fixed BERT embeddings)\n",
    "\n",
    "In this notebook, we consider a **realistic but challenging scenario**: what if we have **no labeled data at all**?\n",
    "\n",
    "In many real-world applications, collecting labeled product-category data is expensive and slow.  \n",
    "Here, we explore how to bootstrap a classification system without any human-provided labels.  \n",
    "Your task is to fill in the blanks and design solutions for this \"zero-label\" setting.\n",
    "\n",
    "---\n",
    "\n",
    "## Key Ideas (Guidelines)\n",
    "\n",
    "1. **Constructing Silver Labels**  \n",
    "   Since we have no ground-truth labels, we must create *weak supervision signals*.  \n",
    "   Possible strategies include:\n",
    "   - **Lexical similarity:** Compare product titles/descriptions with category names using sparse vectors.  \n",
    "   - **Embedding similarity:** Compare BERT embeddings for both products and labels.  \n",
    "   - **Ensemble approaches:** Combine multiple weak signals (e.g., weighted voting between lexical-based and embedding-based similarity).\n",
    "\n",
    "2. **Learning with Silver Labels**  \n",
    "   Once silver labels are generated, train a classifier as if they were real labels.  \n",
    "   To improve robustness, you may consider various techniques that we learned, including (but not limited to):\n",
    "   - **Self-training:** Train an initial model with silver labels, then use it to assign pseudo-labels to unlabeled data with high confidence.  \n",
    "   - **Label embedding models:** Instead of treating labels as arbitrary IDs, use semantic embeddings of label names to guide classification (e.g., inner-product classifier).\n",
    "   - **Consistency regularization:** Encourage the model to produce stable predictions under input perturbations (e.g., dropout noise, data augmentation). This helps prevent overfitting to noisy silver labels and promotes smoother decision boundaries.\n",
    "   - **Stabilizing model prediction using Ensemble:** To mitigate the noise from weak or unstable supervision, you can stabilize predictions through ensembling techniques (e.g., Temporal ensemble via EMA, independent model ensemble).\n",
    "\n",
    "---\n",
    "\n",
    "## Your Tasks\n",
    "\n",
    "1. Generate silver labels.\n",
    "2. Train a classifier using these silver labels and various learning strategies.\n",
    "  \n",
    "üí° *Hint:* Think of this as \"bootstrapping\" the learning process ‚Äî even noisy initial signals can become useful when combined with iterative refinement and stabilization techniques.\n",
    "\n",
    "\n",
    "‚ö†Ô∏è **Note**: Do **NOT** use the labeled training set provided in the previous notebook.  \n",
    "In this notebook, you must assume that **no labeled data exists**. Only the following resources are allowed:\n",
    "- Product metadata (titles, descriptions, etc.)\n",
    "- Category names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "075fd1a6-77ce-4a17-9a90-81764a85fa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from utils import * \n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, ConcatDataset\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6f5937f-50c1-43de-b833-204caf5a4026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default paths\n",
    "ROOT = Path(\"dataset\") # Root dataset directory\n",
    "CORPUS_PATH = ROOT / \"corpus.jsonl\" # Product corpus file (JSON Lines): Each line contains a product ID and its associated text description.\n",
    "EMB_PATH = ROOT / \"corpus_bert_mean.pt\"\n",
    "\n",
    "# Task 1: Product category classification\n",
    "LABEL_MAP_PATH = ROOT / \"category_classification\" \n",
    "LABEL2ID_PATH = LABEL_MAP_PATH / \"label2labelid.json\" \n",
    "ID2LABEL_PATH = LABEL_MAP_PATH / \"labelid2label.json\" \n",
    "PID2LABEL_TEST_PATH = LABEL_MAP_PATH / \"pid2labelids_test.json\" \n",
    "LABEL_EMB_PATH = LABEL_MAP_PATH / \"category_labels_bert_mean.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c819562-37b3-4cf1-8969-9d559997458b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pid2text = load_corpus(CORPUS_PATH) # load corpus\n",
    "\n",
    "label2id = load_json(LABEL2ID_PATH)\n",
    "id2label = load_json(ID2LABEL_PATH)\n",
    "pid2label_test = load_json(PID2LABEL_TEST_PATH)\n",
    "\n",
    "# loading pre-trained embeddings\n",
    "corpus_data = torch.load(EMB_PATH)  # {\"ids\": [...], \"embeddings\": Tensor}\n",
    "pid_list = corpus_data[\"ids\"]\n",
    "pid2idx = {pid: i for i, pid in enumerate(pid_list)}\n",
    "embeddings = corpus_data[\"embeddings\"]\n",
    "\n",
    "label_data = torch.load(LABEL_EMB_PATH)\n",
    "label_emb = label_data[\"embeddings\"].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfc6019-c824-4a6f-aff7-85c3668f473f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# Your Task: Do your magic below \n",
    "# =========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c8e3d5-a984-4989-9cf4-83f34d5b951b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481a1e95-0862-4672-8ffe-aee29e33cc89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "005f00d5-c8dd-4fc3-9606-77bfd65911b3",
   "metadata": {},
   "source": [
    "## Prepare Kaggle submission\n",
    "Modify the code as needed to fit your solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71561bc0-0903-49f5-affb-6bdafbde37ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pathlib import Path\n",
    "\n",
    "# === 1. Load test IDs ===\n",
    "ROOT = Path(\"dataset\") # Root dataset directory\n",
    "LABEL_MAP_PATH = ROOT / \"category_classification\"\n",
    "TEST_IDS_PATH = LABEL_MAP_PATH / \"task1_test_ids.csv\"\n",
    "\n",
    "test_ids_df = pd.read_csv(TEST_IDS_PATH)  # has column \"id\"\n",
    "test_ids = test_ids_df[\"id\"].tolist()\n",
    "\n",
    "# === 2. Custom Dataset (no labels) ===\n",
    "class ProductCategoryTestDataset(Dataset):\n",
    "    def __init__(self, pids, pid2idx, embeddings):\n",
    "        self.pids = pids\n",
    "        self.indices = [pid2idx[pid] for pid in self.pids]\n",
    "        self.vecs = embeddings \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pid = self.pids[idx]\n",
    "        emb = self.vecs[self.indices[idx]]\n",
    "        return {\"X\": torch.tensor(emb, dtype=torch.float)}\n",
    "\n",
    "# === 3. Build dataset and loader ===\n",
    "test_dataset_kaggle = ProductCategoryTestDataset(test_ids, pid2idx, embeddings)\n",
    "test_loader_kaggle = DataLoader(test_dataset_kaggle, batch_size=64)\n",
    "\n",
    "# === 4. Run predictions ===\n",
    "model.eval()\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader_kaggle:\n",
    "        X = batch[\"X\"].to(device)   # or \"cuda\" if using GPU\n",
    "        logits = model(X)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        all_preds.extend(preds.cpu().tolist())\n",
    "\n",
    "# === 5. Build submission file ===\n",
    "submission = pd.DataFrame({\n",
    "    \"id\": test_ids,\n",
    "    \"label\": all_preds\n",
    "})\n",
    "\n",
    "SUBMISSION_PATH = ROOT / \"submission/P3_submission.csv\"\n",
    "submission.to_csv(SUBMISSION_PATH, index=False)\n",
    "\n",
    "print(f\"Submission file saved to {SUBMISSION_PATH}\")\n",
    "print(submission.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esci-env",
   "language": "python",
   "name": "esci-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
